### 简介
---

loki是受promtheus启发的项目，符合云原生标准能够与当下流行的k8s很好的结合在一起，部署和安装都比较方面。loki能够基于promtheus+granafa的监控系统进行部署，比较ELK方便一些。
不需要来回切屏。
loki组件：
- loki: 负责接收promtail发送来的日志流，并提供日志查询接口供grafana查询
- promtail: 一个日志收集代理，可采用daemonset方式部署或者sidecar方式部署
#### daemonset抓取日志原理
- 每个宿主机上均会部署一个promtail的pod
- 每个pod均会挂载宿主机的dockerroot
- promtail通过dockerroot当中读取到相应日志信息
---
### 部署loki on k8s步骤
- 为loki和promtail的配置文件建立configMap
```
wget https://raw.githubusercontent.com/grafana/loki/v2.1.0/cmd/loki/loki-local-config.yaml -O local-config.yaml
kubectl create cm loki-config --from-file=local-config.yaml

```
- 部署loki并配置svc，yaml文件如下：
```
apiVersion: apps/v1
kind: Deployment
metadata:
  creationTimestamp: null
  labels:
    app: loki
  name: loki
spec:
  replicas: 1
  selector:
    matchLabels:
      app: loki
  template:
    metadata:
      labels:
        app: loki
    spec:
      containers:
      - image: grafana/loki:2.1.0
        name: loki
        volumeMounts:
        - name: loki-config
          mountPath: /etc/loki/
      volumes:
      - name: loki-config
        configMap:
          name: loki-config
---
apiVersion: v1
kind: Service
metadata:
  labels:
    app: lokisvc
  name: lokisvc
spec:
  ports:
  - name: web
    port: 3100
    nodePort: 30100
    protocol: TCP
    targetPort: 3100
  selector:
    app: loki
  type: NodePort
```
- 由于采用的是daemonset方式部署promtail,所以promtail不会采用k8s集群的dns，而是宿主机的dns，所以在修改promtail的配置文件当中loki服务地址的名字为lokisvc的ip地址,然后建立为promtail建立configMap
```
kubectl get svc 
[root@master tmp]# kubectl get svc
NAME         TYPE        CLUSTER-IP        EXTERNAL-IP   PORT(S)          AGE
grafana      NodePort    192.168.228.246   <none>        3000:30300/TCP   24h
kubernetes   ClusterIP   192.168.0.1       <none>        443/TCP          21d
loki         NodePort    192.168.7.19      <none>        3100:30100/TCP   24h
promtail     NodePort    192.168.46.226    <none>        9080:30080/TCP   24h
[root@master tmp]# wget https://raw.githubusercontent.com/grafana/loki/v2.1.0/cmd/promtail/promtail-docker-config.yaml -O config.yml
[root@master tmp]# sed -i 's#loki#192.168.7.19#' config.yml
[root@master tmp]# kubectl create cm promtail-config --from-file=config.yml

```
config.yml的配置信息如下：
```
server:
  http_listen_port: 9080
  http_listen_address: 0.0.0.0
  grpc_listen_port: 0
  #log_level: debug
positions:
  filename: /tmp/positions.yaml

clients:
  - url: http://192.168.7.19:3100/loki/api/v1/push
scrape_configs:
- job_name: pods
  kubernetes_sd_configs:
  - role: pod
  # namespaces:
      names: ns
  pipeline_stages:
  - docker: 
  relabel_configs:
  #deamonset当中挂载了宿主机的dockerroot位置，所以在当前目录下即可取到相关日志信息
  - replacement: /var/log/pods/*/$1/*.log
    source_labels:
    - __meta_kubernetes_pod_container_name
    target_label: __path__
  #本次实验主机是抓取nginx的日志，nginx部署在ns命名空间当中，keep了ns的target,其他不匹配的均不抓取日志
  - source_labels: ["__meta_kubernetes_namespace"]
    regex: "ns"
    action: keep

  #配置一个job标签，以方便查询，job的值为namespace/podname 
  - source_labels: ["__meta_kubernetes_namespace","__meta_kubernetes_pod_container_name"]
    separator: /
    replacement: $1
    target_label: job
    action: replace
```

- 以daemonset方式部署promtail，yaml文件如下：
```
#建立一个sa,由于promtail是部署在default空间，而nginx在ns空间，所以要建议跨空间访问的sa
apiVersion: v1
kind: ServiceAccount
metadata:
  name: promtail
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: promtail
  namespace: ns
rules:
- apiGroups:
  - ""
  resources:
  - namespaces
  - pods
  - nodes
  verbs:
  - get
  - list
  - watch
---
apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: promtail
  namespace: ns
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: promtail
subjects:
- kind: ServiceAccount
  name: promtail
  namespace: default
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  labels:
    app: promtail
  name: promtail
spec:
  selector:
    matchLabels:
      app: promtail
  template:
    metadata:
      labels:
        app: promtail
    spec:
      dnsConfig:
        nameservers:
        - 192.168.0.10
        searches:
        - default.svc.cluster.local
        - svc.cluster.local
        - cluster.local
      dnsPolicy: ClusterFirst
      serviceAccount: promtail
      hostNetwork: True
      nodeName: node1
      containers:
      - image: grafana/promtail:2.1.0
        name: promtail
        ports:
        - name: webserver
          containerPort: 9080
        volumeMounts:
        - name: promtail-config
          mountPath: /etc/promtail/
        - name: podlogs
          mountPath: /var/log/pods
    #挂载dockerroot的位置是因为/var/log/pods下的文件是软链接指向dockerroot，promtail不支持读取软链接当中的内容。
        - name: docker
          mountPath: /data/docker/root/containers
      volumes:
      - name: docker
        hostPath:
          path: /data/docker/root/containers
      - name: promtail-config
        configMap:
          name: promtail-config
      - name: podlogs
        hostPath:
          path: /var/log/pods
```
- 部署ng
```
apiVersion: v1
kind: Pod
metadata:
  namespace: ns
  name: nginx
spec:
  nodeName: node1
  containers:
  - name: nginx
    image: nginx
```
- 登陆loki地址，查看内容如下
![1](https://github.com/salarst/note/blob/master/img/loki.png)
当ready=true时表示已成功抓取到信息
- 在grafana上添加datasorce,并使用grafana的explore获取日志信息
![1](https://github.com/salarst/note/blob/master/img/datas.png)
![1](https://github.com/salarst/note/blob/master/img/grafanaex.png)

---
### 遇到的问题
---
- promtail抓取不到日志信息，一直报`stat file xxxx ,no such file or directory`<br>
**报错的原因**: 这是由于没有挂载dockerroot,promtail又不支持从软链接当中读取日志信息。在promtail当中添加一个volumes指向dockeroot并挂载到对应目录下即可
```
volumes:
      - name: docker
        hostPath:
          path: /data/docker/root/containers
---
- name: docker
  mountPath: /data/docker/root/containers
```
- jenkins-slave调用kubectl和docker时，报找不到命令。<br>
**报错原因**： 原生的jnlp镜像是不带docker和k8s命令的。如果jnlp要使用这两个工具，需要在jenkins cloud配置container模板时，添加volumes挂载kubectl，kubeconfig等信息到pod里。具体的jnlp-slave.yaml文件如下
```
apiVersion: v1
kind: Pod
metadata:
  namespace: operate
  name: jnlp-slave
  labels:
     app: jnlp-slave
spec:
  volumes:
  - name: kubeconfig
    secret:
      secretName: kube-admin  #由/root/.kube/config文件生成的secret。
  - name: docker
    hostPath:
      path: /var/run/docker.sock
  - name: image-registry
    configMap: 
      name: regauth  #docker-registry secret
  - name: dockersock
    hostPath:
      path: /var/run/docker.sock
  - name: dockerclient
    hostPath:
	  path: /usr/bin/docker
  - name: kubectl
    hostPath:
	  path: /usr/bin/kubectl
  containers: 
  - name: jnlp-slav
    image: 192.168.33.9:5000/k8s/jenkins/jnlp-slave:3.29
    imagePullPolicy: IfNotPresent
	volumeMounts:
  - name: image-registry
    mountPath: /home/jenkins/.docker
  - name: kubeconfig
    mountPath: /home/jenkins/.kube
  - name: dockersock
    mountPath: /var/run/docker.sock
	- name: dockerclient
	  mountPath: /usr/bin/docker
	- name: kubectl
	  mountPath: /usr/bin/kubectl   
```
